{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "346e23f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>subtitle_entities</th>\n",
       "      <th>keywords_entities</th>\n",
       "      <th>BERT_topic_num</th>\n",
       "      <th>BERT_topic_prob</th>\n",
       "      <th>BERT_keywords</th>\n",
       "      <th>BERT_kw_topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kaotisk nyttarsnatt   ute av kontroll</td>\n",
       "      <td>nyheter</td>\n",
       "      <td>Det har vært en hektisk nyttårsnatt for politi...</td>\n",
       "      <td>nyheter</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['nyttårsnatt', 'politiet', 'hektisk', 'landet...</td>\n",
       "      <td>[22, 120, 89, 109, 159]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fra singel til damemagnet</td>\n",
       "      <td>tema</td>\n",
       "      <td>Ekspertenes beste råd til hvordan du blir attr...</td>\n",
       "      <td>kjæreste,dating,singel</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>12</td>\n",
       "      <td>0.300247</td>\n",
       "      <td>['datingmarkedet', 'attraktiv', 'råd', 'eksper...</td>\n",
       "      <td>[140, 10, 59, 68, 85]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strom nytt fra januar</td>\n",
       "      <td>tema</td>\n",
       "      <td>Nye boligregler, bedre jobbpensjon og dyrere f...</td>\n",
       "      <td>økonomi,pensjon,skatt</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['boligregler', 'endringer', 'dyrere', 'bedre'...</td>\n",
       "      <td>[154, 96, 136, 166, 104]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anders kvitt magefettet i superfart 1</td>\n",
       "      <td>tema</td>\n",
       "      <td>- Hvis folk bare visste hvor enkelt det er, ha...</td>\n",
       "      <td>magefett,vektnedgang,kosthold,styrketrening,</td>\n",
       "      <td>{'Anders Muren': 'PER'}</td>\n",
       "      <td>{}</td>\n",
       "      <td>98</td>\n",
       "      <td>0.939760</td>\n",
       "      <td>['magefettet', 'overflødige', 'enkelt', 'raskt...</td>\n",
       "      <td>[98, 79, 18, 80, 137]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>taus om overgrepsdom</td>\n",
       "      <td>nyheter</td>\n",
       "      <td>Trump ønsket «henne alt godt» i fjor sommer. N...</td>\n",
       "      <td>donald trump,ghislaine maxwell,utenriks,nyhete...</td>\n",
       "      <td>{'Trump': 'PER', 'Ghislaine Maxwell': 'PER', '...</td>\n",
       "      <td>{'donald trump': 'PER', 'usa': 'LOC', 'jeffrey...</td>\n",
       "      <td>93</td>\n",
       "      <td>0.785539</td>\n",
       "      <td>['maxwell', 'trump', 'presidenten', 'unge', 'd...</td>\n",
       "      <td>[8, 93, 7, 32, 54]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Headline Category  \\\n",
       "0  kaotisk nyttarsnatt   ute av kontroll  nyheter   \n",
       "1              fra singel til damemagnet     tema   \n",
       "2                  strom nytt fra januar     tema   \n",
       "3  anders kvitt magefettet i superfart 1     tema   \n",
       "4                   taus om overgrepsdom  nyheter   \n",
       "\n",
       "                                            Subtitle  \\\n",
       "0  Det har vært en hektisk nyttårsnatt for politi...   \n",
       "1  Ekspertenes beste råd til hvordan du blir attr...   \n",
       "2  Nye boligregler, bedre jobbpensjon og dyrere f...   \n",
       "3  - Hvis folk bare visste hvor enkelt det er, ha...   \n",
       "4  Trump ønsket «henne alt godt» i fjor sommer. N...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0                                           nyheter    \n",
       "1                            kjæreste,dating,singel    \n",
       "2                             økonomi,pensjon,skatt    \n",
       "3      magefett,vektnedgang,kosthold,styrketrening,    \n",
       "4  donald trump,ghislaine maxwell,utenriks,nyhete...   \n",
       "\n",
       "                                   subtitle_entities  \\\n",
       "0                                                 {}   \n",
       "1                                                 {}   \n",
       "2                                                 {}   \n",
       "3                            {'Anders Muren': 'PER'}   \n",
       "4  {'Trump': 'PER', 'Ghislaine Maxwell': 'PER', '...   \n",
       "\n",
       "                                   keywords_entities  BERT_topic_num  \\\n",
       "0                                                 {}              -1   \n",
       "1                                                 {}              12   \n",
       "2                                                 {}              -1   \n",
       "3                                                 {}              98   \n",
       "4  {'donald trump': 'PER', 'usa': 'LOC', 'jeffrey...              93   \n",
       "\n",
       "   BERT_topic_prob                                      BERT_keywords  \\\n",
       "0         0.000000  ['nyttårsnatt', 'politiet', 'hektisk', 'landet...   \n",
       "1         0.300247  ['datingmarkedet', 'attraktiv', 'råd', 'eksper...   \n",
       "2         0.000000  ['boligregler', 'endringer', 'dyrere', 'bedre'...   \n",
       "3         0.939760  ['magefettet', 'overflødige', 'enkelt', 'raskt...   \n",
       "4         0.785539  ['maxwell', 'trump', 'presidenten', 'unge', 'd...   \n",
       "\n",
       "             BERT_kw_topics  \n",
       "0   [22, 120, 89, 109, 159]  \n",
       "1     [140, 10, 59, 68, 85]  \n",
       "2  [154, 96, 136, 166, 104]  \n",
       "3     [98, 79, 18, 80, 137]  \n",
       "4        [8, 93, 7, 32, 54]  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bertopic import BERTopic\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "df = pd.read_csv(\"/Users/markuswiikjensen/Downloads/Preprocessed_Data.csv\")\n",
    "df.dropna(inplace=True)\n",
    "df.drop(columns=[\"Link\"], inplace=True)\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e76fcf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Category.str.contains(\"-\") == False]\n",
    "def clean(x: str):\n",
    "    x = x.replace(\"  \", \" \").replace(\"   \", \" \")\n",
    "    if not x.endswith(\".\"):\n",
    "        x += \".\"\n",
    "    return x\n",
    "\n",
    "df.Headline = df.Headline.apply(lambda x: 'Overskrift: ' + clean(x))\n",
    "df.Subtitle = df.Subtitle.apply(lambda x: 'Oppsummering: ' + clean(x))\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "def extract_entities(x1: str, x2: str):\n",
    "    # Crappy string replace due to the column-values not being standardized. Also can't replace all \"'\" with '\"' because of the \"it's\" in the text (and the likes)\n",
    "    x1 = x1.replace(\"{'\", '{\"').replace(\"'}\", '\"}').replace(\"':\", '\":').replace(\"',\", '\",').replace(\": '\", ': \"').replace(\", '\", ', \"')\n",
    "    x2 = x2.replace(\"{'\", '{\"').replace(\"'}\", '\"}').replace(\"':\", '\":').replace(\"',\", '\",').replace(\": '\", ': \"').replace(\", '\", ', \"')\n",
    "    result = ''\n",
    "    people = []\n",
    "    locations = []\n",
    "    organizations = []\n",
    "    if (len(x1) > 2):\n",
    "        string_dict = json.loads(x1)\n",
    "        # Get keys and values where values are equal to 'PER'\n",
    "        for key, value in string_dict.items():\n",
    "            if value == 'PER':\n",
    "                people.append(key)\n",
    "            elif value == 'LOC':\n",
    "                locations.append(key)\n",
    "            elif value == 'ORG':\n",
    "                organizations.append(key)\n",
    "    if (len(x2) > 2):\n",
    "        string_dict = json.loads(x2)\n",
    "        # Get keys and values where values are equal to 'PER'\n",
    "        for key, value in string_dict.items():\n",
    "            if value == 'PER':\n",
    "                people.append(key)\n",
    "            elif value == 'LOC':\n",
    "                locations.append(key)\n",
    "            elif value == 'ORG':\n",
    "                organizations.append(key)\n",
    "    if len(people) > 0:\n",
    "        capitalized_people = [person.title() for person in people]\n",
    "        result += 'Personer: ' + ', '.join(capitalized_people) + '. '\n",
    "    if len(locations) > 0:\n",
    "        capitalized_locations = [location.title() for location in locations]\n",
    "        result += 'Lokasjoner: ' + ', '.join(capitalized_locations) + '. '\n",
    "    if len(organizations) > 0:\n",
    "        capitalized_organizations = [organization.title() for organization in organizations]\n",
    "        result += 'Organisasjoner: ' + ', '.join(capitalized_organizations) + '. '\n",
    "    return result\n",
    "\n",
    "df['entities'] = df.apply(lambda x: extract_entities(x['subtitle_entities'], x['keywords_entities']), axis=1)\n",
    "\n",
    "# Remove subtitle_entities and keywords_entities\n",
    "df = df.drop(['subtitle_entities', 'keywords_entities'], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a68f001e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_keywords(x1: str):\n",
    "    x1 = ast.literal_eval(x1)\n",
    "    \n",
    "    result = 'Nøkkelord: ' + ', '.join(x1)\n",
    "    return result[:-1] + '.'\n",
    "\n",
    "df['keywords'] = df.apply(lambda x: extract_keywords(x['BERT_keywords']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "897e31eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['BERT_keywords', 'Keywords'], axis=1, inplace=True)\n",
    "\n",
    "# Drop BERT_topic_prob as well because we won't use it\n",
    "df.drop(['BERT_topic_prob'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4087605",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'topicModel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m topic_model \u001b[38;5;241m=\u001b[39m BERTopic()\n\u001b[0;32m----> 2\u001b[0m topic_model \u001b[38;5;241m=\u001b[39m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtopicModel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/bertopic/_bertopic.py:2192\u001b[0m, in \u001b[0;36mBERTopic.load\u001b[0;34m(cls, path, embedding_model)\u001b[0m\n\u001b[1;32m   2169\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   2171\u001b[0m          path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   2172\u001b[0m          embedding_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2173\u001b[0m     \u001b[38;5;124;03m\"\"\" Loads the model from the specified path\u001b[39;00m\n\u001b[1;32m   2174\u001b[0m \n\u001b[1;32m   2175\u001b[0m \u001b[38;5;124;03m    Arguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2190\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   2191\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2192\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m   2193\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m embedding_model:\n\u001b[1;32m   2194\u001b[0m             topic_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(file)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'topicModel'"
     ]
    }
   ],
   "source": [
    "\n",
    "topic_model = BERTopic()\n",
    "topic_model = topic_model.load(\"topicModel\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba4c9a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topic_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m topic_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate_topic_labels()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'topic_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "topic_labels = topic_model.generate_topic_labels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f311def",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topic_labels = topic_model.generate_topic_labels()\n",
    "topic_label_map = {}\n",
    "\n",
    "for label in topic_labels:\n",
    "    strings = label.split(\"_\")\n",
    "    if strings[0] == '-1':\n",
    "        topic_label_map[strings[0]] = 'ukjent'\n",
    "    else:\n",
    "        topic_label_map[strings[0]] = ', '.join(strings[1:])\n",
    "\n",
    "topic_label_map\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eb1fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_topic(x1: str, x2: str):\n",
    "    x1 = int(x1)\n",
    "    x2 = ast.literal_eval(x2)\n",
    "    x2.append(x1)\n",
    "    result = 'Spådd tema: '\n",
    "    if -1 in x2:\n",
    "        x2.remove(-1)\n",
    "    for i in range(len(x2)):\n",
    "        if i == len(x2) - 1:\n",
    "            result += topic_label_map[str(x2[i])]\n",
    "        else:\n",
    "            result += topic_label_map[str(x2[i])] + ', '\n",
    "    return result + '.'\n",
    "\n",
    "df['topics'] = df.apply(lambda x: extract_topic(x['BERT_topic_num'], x['BERT_kw_topics']), axis=1)    \n",
    "df.drop(['BERT_topic_num', 'BERT_kw_topics'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee2ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['text'] = df.apply(lambda x: x['Headline'] + ' ' + x['Subtitle'] + ' ' + x['entities'] + ' ' + x['keywords'] + ' ' + x['topics'], axis=1)\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa48c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(df)):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(f\"Input to model:\\n\\t{df['text'][i]}\\nTARGET:\\t{df['Category'][i]}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ba3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df = pd.DataFrame(columns = df.Category.unique())\n",
    "final_df['text'] = ''\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cf7198",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index, row in df.iterrows():\n",
    "    final_df.loc[index, row['Category']] = 1\n",
    "    final_df.loc[index, 'text'] = row['text']\n",
    "\n",
    "final_df.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480619b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assert that the sum of columns [nyheter, tema, sport, kjendis, kultur, meninger, annonse, bok, magasinet, okonomi]\n",
    "# is always equal to 1\n",
    "assert (final_df.iloc[:, 0:10].sum(axis=1) == 1).all()\n",
    "# Assert that the df has no NaN values\n",
    "assert final_df.isnull().values.any() == False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14dab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7edf6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df.to_csv('BERT_input_clean.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
